{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd6a99a",
   "metadata": {},
   "source": [
    "# 聚类\n",
    "## K均值聚类\n",
    "\n",
    "### 数学原理\n",
    "> 参考：《Python数学实验与建模》\n",
    ">\n",
    "> [聚类算法优缺点对比（CSDN）](https://blog.csdn.net/weixin_46713695/article/details/125725036?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168880886016782425175195%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168880886016782425175195&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-125725036-null-null.142^v88^insert_down1,239^v2^insert_chatgpt&amp;utm_term=%E4%B8%8D%E5%90%8C%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9&amp;spm=1018.2226.3001.4187)\n",
    "\n",
    "假定样本集中的全体样本可以分为$C$类，并选定$C$个初始聚类中心，然后根据最小距离原则将每个样本分配到某一类中，之后不断迭代计算各类的聚类中心，并依据新的聚类中心调整聚类情况，直到迭代收敛或聚类中心不再改变。\n",
    "\n",
    "K-均值聚类算法最后将总样本集$G$划分成$C$个子集：$G_1,G_2,...,G_C$，他们满足下面条件：\n",
    "\n",
    "1. $G_1 \\cup G_2 \\cup...\\cup G_C=G;$\n",
    "2. $G_i \\cup G_j = \\varnothing (1 \\leq i \\lt j \\leq C)$\n",
    "3. $G_i \\neq \\varnothing, G_i \\neq G (1 \\leq i \\leq C)$\n",
    "\n",
    "设$m_i (i=1,...,C)$为$C$个聚类中心，记\n",
    "\n",
    "$$\n",
    "J_e = \\sum_{i=1}^{C} \\sum_{\\omega\\in G_i} \\lVert \\omega - m_i \\rVert^2\n",
    "$$\n",
    "\n",
    "使$J_e$最小的聚类是误差平方和准则下的最优结果\n",
    "\n",
    "### 优点\n",
    "1. 简单，易于理解和实现\n",
    "2. 时间复杂度低\n",
    "3. 当簇是密集的、球状或团状的，而簇与簇之间区别明显时，它的聚类效果很好\n",
    "\n",
    "### 缺点\n",
    "1. 需要对均值给出定义\n",
    "2. 需要指定要聚类的数目，对 K 值敏感。也就是说，K 的选择会较大程度上影响分类效果\n",
    "3. 对离群点和噪声点敏感，一些过大的异常值会带来很大影响\n",
    "4. 算法对初始聚类中心选择敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da802a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
    "# define the model\n",
    "model = KMeans(n_clusters=2)\n",
    "# fit the model\n",
    "model.fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
